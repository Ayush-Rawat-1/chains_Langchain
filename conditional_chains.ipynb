{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64c58b0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import Literal\n",
    "from langchain_groq import ChatGroq\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "176a4e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "groq_api_key=os.getenv(\"GROQ_API_KEY\")\n",
    "os.environ[\"GROQ_API_KEY\"]=groq_api_key\n",
    "model=ChatGroq(model=\"llama-3.1-8b-instant\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c5405432",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Feedback(BaseModel):\n",
    "    sentiment: Literal[\"positive\",\"negative\"] = Field(description=\"Give the sentiment of the feedback.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "32d67d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser, PydanticOutputParser\n",
    "\n",
    "parser=StrOutputParser()\n",
    "pydatnic_parser=PydanticOutputParser(pydantic_object=Feedback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1d359c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# 1. Sentiment Analysis\n",
    "prompt1=PromptTemplate(\n",
    "    template=\"\"\"Classify the sentiment of the following feedback text into positive or negative.\n",
    "    Feedback: {feedback}\n",
    "    {format_instructions}\"\"\",\n",
    "    input_variables=[\"feedback\"],\n",
    "    partial_variables={\"format_instructions\":pydatnic_parser.get_format_instructions()}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "03e60e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_chain = prompt1 | model | pydatnic_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6a5b6923",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Feedback(sentiment='negative')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = classifier_chain.invoke({\"feedback\":\"This is a terrible smartphone\"})\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fff6257c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema.runnable import RunnableBranch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fd725ae1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nRunnableBranch(\\n    (condition1,chain1),\\n    (condition2,chain2),\\n    default chain\\n)\\n'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "RunnableBranch(\n",
    "    (condition1,chain1),\n",
    "    (condition2,chain2),\n",
    "    default chain\n",
    ")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f396a557",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt2=PromptTemplate(\n",
    "    template=\"Write an response to this positive feedback: {feedback}\",\n",
    "    input_variables=[\"feedback\"]\n",
    ")\n",
    "\n",
    "prompt3=PromptTemplate(\n",
    "    template=\"Write an response to this negative feedback: {feedback}\",\n",
    "    input_variables=[\"feedback\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f53fc5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "branch_chain = RunnableBranch(\n",
    "    (lambda x: x.sentiment == \"positive\", prompt2 | model | parser),\n",
    "    (lambda x: x.sentiment == \"negative\", prompt3 | model | parser),\n",
    "    lambda x: \"Failed!\"  # By default changes to RunnableLambda\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "518504a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBranch(branches=[(RunnableLambda(lambda x: x.sentiment == 'positive'), PromptTemplate(input_variables=['feedback'], input_types={}, partial_variables={}, template='Write an response to this positive feedback: {feedback}')\n",
       "| ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x000001F9BD0D2750>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x000001F9BE28CD10>, model_name='llama-3.1-8b-instant', model_kwargs={}, groq_api_key=SecretStr('**********'))\n",
       "| StrOutputParser()), (RunnableLambda(lambda x: x.sentiment == 'negative'), PromptTemplate(input_variables=['feedback'], input_types={}, partial_variables={}, template='Write an response to this negative feedback: {feedback}')\n",
       "| ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x000001F9BD0D2750>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x000001F9BE28CD10>, model_name='llama-3.1-8b-instant', model_kwargs={}, groq_api_key=SecretStr('**********'))\n",
       "| StrOutputParser())], default=RunnableLambda(lambda x: 'Failed!'))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "branch_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1cd6c0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = classifier_chain | branch_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5c904cd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I apologize that our product/service did not meet your expectations. Can you please provide more details about your experience so we can better understand what went wrong and how we can improve? Your feedback is invaluable to us, and we appreciate your honesty. \\n\\nIf there's anything we can do to rectify the situation, please let us know and we'll do our best to resolve the issue. We're committed to providing the best possible experience for our customers, and we'll use your feedback to make positive changes in the future.\""
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"feedback\" : \"This is a terrible Smartphone.\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9406e203",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    +-------------+      \n",
      "    | PromptInput |      \n",
      "    +-------------+      \n",
      "            *            \n",
      "            *            \n",
      "            *            \n",
      "   +----------------+    \n",
      "   | PromptTemplate |    \n",
      "   +----------------+    \n",
      "            *            \n",
      "            *            \n",
      "            *            \n",
      "      +----------+       \n",
      "      | ChatGroq |       \n",
      "      +----------+       \n",
      "            *            \n",
      "            *            \n",
      "            *            \n",
      "+----------------------+ \n",
      "| PydanticOutputParser | \n",
      "+----------------------+ \n",
      "            *            \n",
      "            *            \n",
      "            *            \n",
      "       +--------+        \n",
      "       | Branch |        \n",
      "       +--------+        \n",
      "            *            \n",
      "            *            \n",
      "            *            \n",
      "    +--------------+     \n",
      "    | BranchOutput |     \n",
      "    +--------------+     \n"
     ]
    }
   ],
   "source": [
    "chain.get_graph().print_ascii()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
